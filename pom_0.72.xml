<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<groupId>scala_demo</groupId>
	<artifactId>scala_demo</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<name>${project.artifactId}</name>
	<description>This is a boilerplate maven project to start using Spark in Scala</description>
	<inceptionYear>2019</inceptionYear>

	<properties>
		<maven.compiler.source>1.7</maven.compiler.source>
		<maven.compiler.target>1.7</maven.compiler.target>
		<encoding>UTF-8</encoding>
		<!-- Put the Scala version of the cluster -->
		<scala.version>2.11.8</scala.version>
		<scala.binary.version>2.11</scala.binary.version>
		<spark.version>2.3.0</spark.version>
		<xgboost4j-spark.version>0.72</xgboost4j-spark.version>
	</properties>

	<!-- repository to add org.apache.spark -->
	<repositories>
		<repository>
			<id>cloudera-repo-releases</id>
			<url>https://repository.cloudera.com/artifactory/repo/</url>
		</repository>
	</repositories>

	<build>
		<sourceDirectory>src/main/scala</sourceDirectory>
		<testSourceDirectory>src/test/scala</testSourceDirectory>
		<plugins>
			<plugin>
				<!-- see http://davidb.github.com/scala-maven-plugin -->
				<!-- https://mvnrepository.com/artifact/net.alchim31.maven/scala-maven-plugin -->
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
				<!-- <version>3.1.3</version> -->
				<version>4.0.2</version>
				<executions>
					<execution>
						<goals>
							<goal>compile</goal>
							<goal>testCompile</goal>
						</goals>
						<configuration>
							<args>
								<arg>-dependencyfile</arg>
								<arg>${project.build.directory}/.scala_dependencies</arg>
							</args>
						</configuration>
					</execution>
				</executions>
			</plugin>

			<!-- 通过该执行JUnit或者TestNG的测试用例 -->
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-surefire-plugin</artifactId>
				<!-- <version>2.13</version> -->
				<version>3.0.0-M1</version>
				<configuration>
					<useFile>false</useFile>
					<disableXmlReport>true</disableXmlReport>
					<!-- If you have classpath issue like NoDefClassError,... -->
					<!-- useManifestOnlyJar>false</useManifestOnlyJar -->
					<includes>
						<include>**/*Test.*</include>
						<include>**/*Suite.*</include>
					</includes>
				</configuration>
			</plugin>

			<!-- 将程序代码以及依赖项或依赖模块捆绑在一起打包的方式 -->
			<plugin>
				<artifactId>maven-assembly-plugin</artifactId>
				<!-- <version>2.4.1</version> -->
				<version>3.1.1</version>
				<configuration>
					<descriptorRefs>
						<descriptorRef>jar-with-dependencies</descriptorRef>
					</descriptorRefs>
				</configuration>
				<executions>
					<execution>
						<id>make-assembly</id>
						<phase>package</phase>
						<goals>
							<goal>single</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>

	<dependencies>
		<!-- Scala and Spark dependencies -->
		<!-- https://mvnrepository.com/artifact/org.scala-lang/scala-library -->
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
		</dependency>
		<!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<!-- https://mvnrepository.com/artifact/org.apache.spark/spark-mllib -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<!-- https://mvnrepository.com/artifact/ml.dmlc/xgboost4j-spark -->
		<dependency>
			<groupId>ml.dmlc</groupId>
			<artifactId>xgboost4j-spark</artifactId>
			<version>${xgboost4j-spark.version}</version>
		</dependency>
	</dependencies>
</project>

